seX = seX,
Y = sign(X)*Y,
seY = seY,
m_x = MCEM_fit1$paramEst$m_X,
lambda_x = MCEM_fit1$paramEst$lambdaX,
pis = as.array(MCEM_fit1$paramEst$pis),
mus = as.numeric(MCEM_fit1$paramEst$mus),
sds = as.numeric(MCEM_fit1$paramEst$sds)
)
MR_stan1 = stan(file = "MR_sampling.stan", data = data1)
array(MCEM_fit1$paramEst$pis, dim = )
array(MCEM_fit1$paramEst$pis, dim = 1)
tmp = array(MCEM_fit1$paramEst$pis, dim = 1)
data1 = list(p = p,
K = K,
X = abs(X),
seX = seX,
Y = sign(X)*Y,
seY = seY,
m_x = MCEM_fit1$paramEst$m_X,
lambda_x = MCEM_fit1$paramEst$lambdaX,
pis = array(MCEM_fit1$paramEst$pis, dim = 1),
mus = as.numeric(MCEM_fit1$paramEst$mus),
sds = as.numeric(MCEM_fit1$paramEst$sds)
)
MR_stan1 = stan(file = "MR_sampling.stan", data = data1)
data1 = list(p = p,
K = K,
X = abs(X),
seX = seX,
Y = sign(X)*Y,
seY = seY,
m_x = MCEM_fit1$paramEst$m_X,
lambda_x = MCEM_fit1$paramEst$lambdaX,
pis = array(MCEM_fit1$paramEst$pis, dim = 1),
mus = array(MCEM_fit1$paramEst$mus, dim = 1),
sds = array(MCEM_fit1$paramEst$sds, dim = 1)
)
MR_stan1 = stan(file = "MR_sampling.stan", data = data1)
log_lik1 = extract_log_lik(MR_stan1, merge_chains = FALSE)
r_eff1 <- relative_eff(exp(log_lik1))
loo1 <- loo(log_lik1, r_eff = r_eff1)
loo1
loo_compare(loo1, loo2, loo3)
? stan
selectModel_stan = function(X, Y, seX, seY, K_range = 1:3, Nreps = 15,
verbose=FALSE) {
loo_list = list()
for (K in K_range) {
## Choose initial values that maximizes likelihood
initVals = optimizeInitVals(K, X, Y, seX, seY, Nreps = Nreps, verbose=verbose)
## Run MC-EM with optimized initial values
MCEM_fit = MR_EM(K, initVals, X, Y, seX, seY, saveTraj=FALSE, computeSE=FALSE)
## Sampling with stan
MR_stan_code = "
data {
// sample size
int<lower=0> p;
// # clusters
int<lower=0> K;
// data
real<lower=0> X[p];
real<lower=0> seX[p];
real Y[p];
real<lower=0> seY[p];
// param estimates
real m_x;
real<lower=0> lambda_x;
vector[K] pis;
vector[K] mus;
vector[K] sds;
}
parameters {
real<lower=0> muX[p];
real beta[p];
}
model {
// prior for muX
muX ~ normal(m_x, lambda_x);
for (i in 1:p) {
real cluster_logliks[K];
// prior for beta[i]
for (k in 1:K) {
cluster_logliks[k] = log(pis[k]) +  normal_lpdf(beta[i] | mus[k], sds[k]);
}
target += log_sum_exp(cluster_logliks);
// likelihood for X[i]
target += normal_lpdf(X[i] | muX[i], seX[i]);
// likelihood for Y[i]
target += normal_lpdf(Y[i] | muX[i]*beta[i], seY[i]);
}
}
generated quantities {
vector[p] log_lik;
for (i in 1:p) {
log_lik[i] = normal_lpdf(X[i] | muX[i], seX[i]) +
normal_lpdf(Y[i] | beta[i]*muX[i], seY[i]);
}
}
"
data = list(p = length(X),
K = K,
X = abs(X),
seX = seX,
Y = sign(X)*Y,
seY = seY,
m_x = MCEM_fit$paramEst$m_X,
lambda_x = MCEM_fit$paramEst$lambdaX,
pis = array(MCEM_fit$paramEst$pis, dim = 1),
mus = array(MCEM_fit$paramEst$mus, dim = 1),
sds = array(MCEM_fit$paramEst$sds, dim = 1)
)
MR_stan = stan(model_code = MR_stan_code, chains = 2)
log_lik = extract_log_lik(MR_stan, merge_chains = FALSE)
r_eff <- relative_eff(exp(log_lik))
loo_list[[K]] = loo(log_lik, r_eff = r_eff)
}
loo::loo_compare(x = loo_list)
}
mod_select = selectModel_stan(X, Y, seX, seY, verbose=TRUE)
length(X)
MR_stan_code
## Sampling with stan
MR_stan_code = "
data {
// sample size
int<lower=0> p;
// # clusters
int<lower=0> K;
// data
real<lower=0> X[p];
real<lower=0> seX[p];
real Y[p];
real<lower=0> seY[p];
// param estimates
real m_x;
real<lower=0> lambda_x;
vector[K] pis;
vector[K] mus;
vector[K] sds;
}
parameters {
real<lower=0> muX[p];
real beta[p];
}
model {
// prior for muX
muX ~ normal(m_x, lambda_x);
for (i in 1:p) {
real cluster_logliks[K];
// prior for beta[i]
for (k in 1:K) {
cluster_logliks[k] = log(pis[k]) +  normal_lpdf(beta[i] | mus[k], sds[k]);
}
target += log_sum_exp(cluster_logliks);
// likelihood for X[i]
target += normal_lpdf(X[i] | muX[i], seX[i]);
// likelihood for Y[i]
target += normal_lpdf(Y[i] | muX[i]*beta[i], seY[i]);
}
}
generated quantities {
vector[p] log_lik;
for (i in 1:p) {
log_lik[i] = normal_lpdf(X[i] | muX[i], seX[i]) +
normal_lpdf(Y[i] | beta[i]*muX[i], seY[i]);
}
}
"
MR_stan_code
selectModel_stan = function(X, Y, seX, seY, K_range = 1:3, Nreps = 15,
verbose=FALSE) {
loo_list = list()
for (K in K_range) {
## Choose initial values that maximizes likelihood
initVals = optimizeInitVals(K, X, Y, seX, seY, Nreps = Nreps, verbose=verbose)
## Run MC-EM with optimized initial values
MCEM_fit = MR_EM(K, initVals, X, Y, seX, seY, saveTraj=FALSE, computeSE=FALSE)
## Sampling with stan
MR_stan_code = "
data {
// sample size
int<lower=0> p;
// # clusters
int<lower=0> K;
// data
real<lower=0> X[p];
real<lower=0> seX[p];
real Y[p];
real<lower=0> seY[p];
// param estimates
real m_x;
real<lower=0> lambda_x;
vector[K] pis;
vector[K] mus;
vector[K] sds;
}
parameters {
real<lower=0> muX[p];
real beta[p];
}
model {
// prior for muX
muX ~ normal(m_x, lambda_x);
for (i in 1:p) {
real cluster_logliks[K];
// prior for beta[i]
for (k in 1:K) {
cluster_logliks[k] = log(pis[k]) +  normal_lpdf(beta[i] | mus[k], sds[k]);
}
target += log_sum_exp(cluster_logliks);
// likelihood for X[i]
target += normal_lpdf(X[i] | muX[i], seX[i]);
// likelihood for Y[i]
target += normal_lpdf(Y[i] | muX[i]*beta[i], seY[i]);
}
}
generated quantities {
vector[p] log_lik;
for (i in 1:p) {
log_lik[i] = normal_lpdf(X[i] | muX[i], seX[i]) +
normal_lpdf(Y[i] | beta[i]*muX[i], seY[i]);
}
}
"
data = list(p = length(X),
K = K,
X = abs(X),
seX = seX,
Y = sign(X)*Y,
seY = seY,
m_x = MCEM_fit$paramEst$m_X,
lambda_x = MCEM_fit$paramEst$lambdaX,
pis = array(MCEM_fit$paramEst$pis, dim = 1),
mus = array(MCEM_fit$paramEst$mus, dim = 1),
sds = array(MCEM_fit$paramEst$sds, dim = 1)
)
MR_stan = stan(model_code = MR_stan_code, data = data, chains = 2)
log_lik = extract_log_lik(MR_stan, merge_chains = FALSE)
r_eff <- relative_eff(exp(log_lik))
loo_list[[K]] = loo(log_lik, r_eff = r_eff)
}
loo::loo_compare(x = loo_list)
}
mod_select = selectModel_stan(X, Y, seX, seY, verbose=TRUE)
? sampling
selectModel_stan = function(X, Y, seX, seY, K_range = 1:3, Nreps = 15,
verbose=FALSE) {
MR_stancode = "
data {
// sample size
int<lower=0> p;
// # clusters
int<lower=0> K;
// data
real<lower=0> X[p];
real<lower=0> seX[p];
real Y[p];
real<lower=0> seY[p];
// param estimates
real m_x;
real<lower=0> lambda_x;
vector[K] pis;
vector[K] mus;
vector[K] sds;
}
parameters {
real<lower=0> muX[p];
real beta[p];
}
model {
// prior for muX
muX ~ normal(m_x, lambda_x);
for (i in 1:p) {
real cluster_logliks[K];
// prior for beta[i]
for (k in 1:K) {
cluster_logliks[k] = log(pis[k]) +  normal_lpdf(beta[i] | mus[k], sds[k]);
}
target += log_sum_exp(cluster_logliks);
// likelihood for X[i]
target += normal_lpdf(X[i] | muX[i], seX[i]);
// likelihood for Y[i]
target += normal_lpdf(Y[i] | muX[i]*beta[i], seY[i]);
}
}
generated quantities {
vector[p] log_lik;
for (i in 1:p) {
log_lik[i] = normal_lpdf(X[i] | muX[i], seX[i]) +
normal_lpdf(Y[i] | beta[i]*muX[i], seY[i]);
}
}
"
MR_stanmod = stan_model(model_code = MR_stancode)
loo_list = list()
for (K in K_range) {
## Choose initial values that maximizes likelihood
initVals = optimizeInitVals(K, X, Y, seX, seY, Nreps = Nreps, verbose=verbose)
## Run MC-EM with optimized initial values
MCEM_fit = MR_EM(K, initVals, X, Y, seX, seY, saveTraj=FALSE, computeSE=FALSE)
## Sampling with stan
data = list(p = length(X),
K = K,
X = abs(X),
seX = seX,
Y = sign(X)*Y,
seY = seY,
m_x = MCEM_fit$paramEst$m_X,
lambda_x = MCEM_fit$paramEst$lambdaX,
pis = array(MCEM_fit$paramEst$pis, dim = K),
mus = array(MCEM_fit$paramEst$mus, dim = K),
sds = array(MCEM_fit$paramEst$sds, dim = K)
)
MR_stan = sampling(MR_stanmod, data = data, chains = 2)
log_lik = extract_log_lik(MR_stan, merge_chains = FALSE)
r_eff <- relative_eff(exp(log_lik))
loo_list[[K]] = loo(log_lik, r_eff = r_eff)
}
loo::loo_compare(x = loo_list)
}
mod_select = selectModel_stan(X, Y, seX, seY, verbose=TRUE)
mod_select
selectModel_stan = function(X, Y, seX, seY, K_range = 1:3, Nreps = 15,
verbose=FALSE) {
MR_stancode = "
data {
// sample size
int<lower=0> p;
// # clusters
int<lower=0> K;
// data
real<lower=0> X[p];
real<lower=0> seX[p];
real Y[p];
real<lower=0> seY[p];
// param estimates
real m_x;
real<lower=0> lambda_x;
vector[K] pis;
vector[K] mus;
vector[K] sds;
}
parameters {
real<lower=0> muX[p];
real beta[p];
}
model {
// prior for muX
muX ~ normal(m_x, lambda_x);
for (i in 1:p) {
real cluster_logliks[K];
// prior for beta[i]
for (k in 1:K) {
cluster_logliks[k] = log(pis[k]) +  normal_lpdf(beta[i] | mus[k], sds[k]);
}
target += log_sum_exp(cluster_logliks);
// likelihood for X[i]
target += normal_lpdf(X[i] | muX[i], seX[i]);
// likelihood for Y[i]
target += normal_lpdf(Y[i] | muX[i]*beta[i], seY[i]);
}
}
generated quantities {
vector[p] log_lik;
for (i in 1:p) {
log_lik[i] = normal_lpdf(X[i] | muX[i], seX[i]) +
normal_lpdf(Y[i] | beta[i]*muX[i], seY[i]);
}
}
"
MR_stanmod = stan_model(model_code = MR_stancode)
loo_list = list()
for (K in K_range) {
## Choose initial values that maximizes likelihood
initVals = optimizeInitVals(K, X, Y, seX, seY, Nreps = Nreps, verbose=verbose)
## Run MC-EM with optimized initial values
MCEM_fit = MR_EM(K, initVals, X, Y, seX, seY, saveTraj=FALSE, computeSE=FALSE)
## Sampling with stan
data = list(p = length(X),
K = K,
X = abs(X),
seX = seX,
Y = sign(X)*Y,
seY = seY,
m_x = MCEM_fit$paramEst$m_X,
lambda_x = MCEM_fit$paramEst$lambdaX,
pis = array(MCEM_fit$paramEst$pis, dim = K),
mus = array(MCEM_fit$paramEst$mus, dim = K),
sds = array(MCEM_fit$paramEst$sds, dim = K)
)
MR_stan = sampling(MR_stanmod, data = data)
log_lik = extract_log_lik(MR_stan, merge_chains = FALSE)
r_eff <- relative_eff(exp(log_lik))
loo_list[[K]] = loo(log_lik, r_eff = r_eff)
}
loo::loo_compare(x = loo_list)
}
mod_select = selectModel_stan(X, Y, seX, seY, verbose=TRUE)
mod_select
hist((Y/X))
library(Rcpp)
library(RcppArmadillo)
library(MASS)
library(loo)
library(rstan)
# library(profmem)
setwd("~/Dropbox/MR_Bayes/MR-MCEM")
# setwd("GreatLakes/MR-MCEM")
##### Load MR_EM function
# sourceCpp("MR.MCEM/src/MR_EM.cpp")
library(MR.MCEM)
#### Load sampleLatentVarPost
# sourceCpp("MR.MCEM/src/sampleLatentVarPost.cpp")
# source("fisherInfo.R")
set.seed(8686)
p <- 100
seX <- 1 / sqrt(rgamma(p, 7, 0.0002))
seY <- 1 / sqrt(rgamma(p, 7, 0.0002))
# par(mfrow = c(1,2))
# hist(seX)
# hist(seY)
###### set true parameters
# K <- 3
# m_X <- 0
# lambdaX <- 0.5
# pis <- c(0.3, 0.4, 0.3)
# mus <- c(-3, 0, 3)
# sds <- c(0.15, 0.20, 0.05)
###### set true parameters
K <- 2
m_X <- 0
lambdaX <- 0.5
pis <- c(0.7, 0.3)
mus <- c(-1, 1)
sds <- rep(0.20, K)
true.params <- c(m_X, lambdaX^2, sapply(1:K, function(k) c(pis[k], mus[k], sds[k]^2)))
names(true.params) <- c("m_X", "lambdaX2",
as.character(sapply(1:K, function(k) paste(c("pi", "mu", "var"), k, sep = ""))))
###### Simulate data
muX <- rnorm(p, m_X, lambdaX)
Z <- sample(1:K, p, replace=TRUE, prob = pis)
# beta <- sds[Z] * rt(p, df) + mus[Z]
beta <- mvrnorm(1, mus[Z], diag(sds[Z]^2))
X <- mvrnorm(1, muX, diag(seX^2))
Y <- mvrnorm(1, beta*muX, diag(seY^2))
p <- 500
library(Rcpp)
library(RcppArmadillo)
library(MASS)
library(loo)
library(rstan)
# library(profmem)
setwd("~/Dropbox/MR_Bayes/MR-MCEM")
# setwd("GreatLakes/MR-MCEM")
##### Load MR_EM function
# sourceCpp("MR.MCEM/src/MR_EM.cpp")
library(MR.MCEM)
#### Load sampleLatentVarPost
# sourceCpp("MR.MCEM/src/sampleLatentVarPost.cpp")
# source("fisherInfo.R")
set.seed(8686)
p <- 500
seX <- 1 / sqrt(rgamma(p, 7, 0.0002))
seY <- 1 / sqrt(rgamma(p, 7, 0.0002))
# par(mfrow = c(1,2))
# hist(seX)
# hist(seY)
###### set true parameters
# K <- 3
# m_X <- 0
# lambdaX <- 0.5
# pis <- c(0.3, 0.4, 0.3)
# mus <- c(-3, 0, 3)
# sds <- c(0.15, 0.20, 0.05)
###### set true parameters
K <- 2
m_X <- 0
lambdaX <- 0.5
pis <- c(0.7, 0.3)
mus <- c(-1, 1)
sds <- rep(0.20, K)
true.params <- c(m_X, lambdaX^2, sapply(1:K, function(k) c(pis[k], mus[k], sds[k]^2)))
names(true.params) <- c("m_X", "lambdaX2",
as.character(sapply(1:K, function(k) paste(c("pi", "mu", "var"), k, sep = ""))))
###### Simulate data
muX <- rnorm(p, m_X, lambdaX)
Z <- sample(1:K, p, replace=TRUE, prob = pis)
# beta <- sds[Z] * rt(p, df) + mus[Z]
beta <- mvrnorm(1, mus[Z], diag(sds[Z]^2))
X <- mvrnorm(1, muX, diag(seX^2))
Y <- mvrnorm(1, beta*muX, diag(seY^2))
mod_select = selectModel_stan(X, Y, seX, seY, verbose=TRUE)
mod_select
K = 2
initVals = optimizeInitVals(K, X, Y, seX, seY, verbose = TRUE)
MCEM_fit = MR_EM(K, initVals, X, Y, seX, seY, verbose = TRUE)
MCEM_fit
MCEM_fit$convergenceInfo$completeDataLogLik
as.character(1)
? which.max
library(Rcpp)
# Rcpp.package.skeleton("MR.MCEM")
setwd("MR.MCEM")
usethis::use_gpl3_license("Daniel Iong")
compileAttributes(verbose=TRUE)
devtools::load_all()
devtools::document()
devtools::check()
devtools::build()
pkgbuild::check_build_tools(debug=TRUE)
pkgbuild::check_build_tools(debug=TRUE)
